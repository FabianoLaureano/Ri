{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import defaultdict\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>titulo</th>\n",
       "      <th>subTitulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>url</th>\n",
       "      <th>idNoticia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>PT espera 30 mil pessoas em festa na Esplanada</td>\n",
       "      <td>Objetivo é demonstrar apoio popular a Dilma e ...</td>\n",
       "      <td>BRASÍLIA - Após o desgaste provocado com o lan...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Alckmin toma posse de olho no Planalto</td>\n",
       "      <td>Governador reeleito tenta amarrar tucanos paul...</td>\n",
       "      <td>Reeleito em outubro, o governador tucano Geral...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td>Seis obstáculos e desafios do segundo mandato ...</td>\n",
       "      <td>Em meio a escândalo de corrupção, presidente t...</td>\n",
       "      <td>1. Rearranjo das contas A nova equipe econôm...</td>\n",
       "      <td>http://politica.estadao.com.br/noticias/geral,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-12-31T00:00:00Z</td>\n",
       "      <td></td>\n",
       "      <td>Veja as principais fotos do dia e dos eventos ...</td>\n",
       "      <td></td>\n",
       "      <td>http://fotos.estadao.com.br/fotos/politica,dil...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              timestamp                                             titulo  \\\n",
       "0  2014-12-31T00:00:00Z     PT espera 30 mil pessoas em festa na Esplanada   \n",
       "1  2014-12-31T00:00:00Z             Alckmin toma posse de olho no Planalto   \n",
       "2  2014-12-31T00:00:00Z  Seis obstáculos e desafios do segundo mandato ...   \n",
       "3  2014-12-31T00:00:00Z                                                      \n",
       "4  2014-12-31T00:00:00Z                                                      \n",
       "\n",
       "                                           subTitulo  \\\n",
       "0  Objetivo é demonstrar apoio popular a Dilma e ...   \n",
       "1  Governador reeleito tenta amarrar tucanos paul...   \n",
       "2  Em meio a escândalo de corrupção, presidente t...   \n",
       "3  Veja as principais fotos do dia e dos eventos ...   \n",
       "4  Veja as principais fotos do dia e dos eventos ...   \n",
       "\n",
       "                                            conteudo  \\\n",
       "0  BRASÍLIA - Após o desgaste provocado com o lan...   \n",
       "1  Reeleito em outubro, o governador tucano Geral...   \n",
       "2    1. Rearranjo das contas A nova equipe econôm...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                                 url  idNoticia  \n",
       "0  http://politica.estadao.com.br/noticias/geral,...          1  \n",
       "1  http://politica.estadao.com.br/noticias/geral,...          2  \n",
       "2  http://politica.estadao.com.br/noticias/geral,...          3  \n",
       "3  http://fotos.estadao.com.br/fotos/politica,dil...          4  \n",
       "4  http://fotos.estadao.com.br/fotos/politica,dil...          5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"estadao_noticias_eleicao.csv\", encoding=\"utf-8\")\n",
    "news = news.replace(np.nan, '', regex = True)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = news.titulo + \" \" + news.subTitulo + \" \" + news.conteudo\n",
    "content = content.fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escreva uma função que receba uma coleção de documentos e retorne uma matrix de termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas).\n",
    "\n",
    "Essa parte do código foi disponibilizado nesse link https://github.com/allansales/information-retrieval/blob/master/Lab%202/coocurrence_matrix.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    n = len(vocab)\n",
    "   \n",
    "    vocab_to_index = {word:i for i, word in enumerate(vocab)}\n",
    "    \n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    I=list()\n",
    "    J=list()\n",
    "    V=list()\n",
    "    \n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "\n",
    "        I.append(vocab_to_index[previous])\n",
    "        J.append(vocab_to_index[current])\n",
    "        V.append(count)\n",
    "        \n",
    "    co_occurrence_matrix = sparse.coo_matrix((V,(I,J)), shape=(n,n))\n",
    "\n",
    "    return co_occurrence_matrix, vocab_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens_lists = content.apply(lambda text: tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ = stopwords.words('portuguese')\n",
    "filtered_tokens = tokens_lists.apply(lambda tokens: [token for token in tokens if token not in stopword_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [token for tokens_list in filtered_tokens for token in tokens_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, vocab = co_occurrence_matrix(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "consultable_matrix = matrix.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consult_frequency(w1, w2):\n",
    "    return(consultable_matrix[vocab[w1],vocab[w2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorneas top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente inverter o vocab, de forma que as chaves sejam os números e os valores as palavras, para facilitara na busca pelo top 3 de co-ocorrência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_vocab = {vocab[key]: key for key in vocab}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feito isso na função top3 vamos utilizar a consultable_matrix, que contém as quantidades de co-ocorrências de cada palavra com todas as outras do corpus, e pegar a linha dessa matrix correspondente as co-ocorrências da palavra que queremos transformar em um array, onde cada posição está relacionada com a chave do i_vocab, por exemplo, a posição 1 do array co_ocorr_words, contém a quantidade de co-ocorrências de word com a palavra retornada de i_vocab[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top3(word):\n",
    "    co_ocorr_words = np.reshape(consultable_matrix[vocab[word]].toarray(), -1)\n",
    "    \n",
    "    dic = {}\n",
    "    \n",
    "    for i in range(len(co_ocorr_words)):\n",
    "        dic[i_vocab[i]] = co_ocorr_words[i]\n",
    "        \n",
    "    return sorted(dic.items(), key=lambda x: x[1], reverse = True)[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanda a consulta original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora a nova consulta será composta pela consulta original mais as palavras retornadas do top3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(word):\n",
    "    query = []\n",
    "    query.append(word)\n",
    "    query.extend(i[0] for i in top3(word))\n",
    "    \n",
    "    return \" \".join(i for i in query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_tokens(df):\n",
    "    indexes = defaultdict(set)\n",
    "    for index,row in df.iterrows():\n",
    "        if isinstance(row['titulo'], str):\n",
    "            titulo_tokens = (word.lower() for word in (nltk.word_tokenize(row['titulo'])))\n",
    "        if isinstance(row['subTitulo'], str):\n",
    "            subTitulo_tokens = (word.lower() for word in (nltk.word_tokenize(row['subTitulo'])))\n",
    "        if isinstance(row['conteudo'], str):\n",
    "            conteudo_tokens = (word.lower() for word in (nltk.word_tokenize(row['conteudo'])))\n",
    "            a = Counter(word.lower() for word in (nltk.word_tokenize(row['conteudo']))) #TF (term frequency)\n",
    "        #if isinstance(row['url'], str):\n",
    "            #url_tokens = (word.lower() for word in (nl.word_tokenize(row['url'])))\n",
    "        \n",
    "        \n",
    "        for token in titulo_tokens:\n",
    "            indexes[token].add( (int(row['idNoticia']), a[token]) )\n",
    "                \n",
    "        for token in subTitulo_tokens:\n",
    "            indexes[token].add( (int(row['idNoticia']), a[token]) )\n",
    "\n",
    "        for token in conteudo_tokens:\n",
    "            indexes[token].add( ( int(row['idNoticia']), a[token] ) )\n",
    "            \n",
    "        #for token in url_tokens:\n",
    "            #indexes[token].add( (int(row['idNoticia']), a[token]) )\n",
    "        \n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = gera_tokens(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(word):\n",
    "    \n",
    "    docs = dic[word]\n",
    "    \n",
    "    return [doc[0] for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escolhendo os termos dilma, aécio e discriminalização para serem a consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quais os termos retornados para a expansão de cada consulta?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dilma rousseff disse é\n",
      "aécio neves disse é\n",
      "descriminalização aborto maconha drogas\n"
     ]
    }
   ],
   "source": [
    "print(expand('dilma'))\n",
    "print(expand('aécio'))\n",
    "print(expand('descriminalização'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Você acha que esses termos são de fato relacionados com a consulta original?\n",
    "\n",
    "Com exceção das palavras 'disse' e 'é', os demais termos tem relação com os termos, já que rousseff e neves são sobrenomes de dilma e aécio, e aborto, maconha e drogas são coisas bem ligadas ao assunto de decriminalização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare os documentos retornados para a consulta original com a consulta expandida. Quais resultados você acha que melhor capturam a necessidade de informação do usuário? Por que?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em relação as consultas pelos termos 'dilma', 'aécio', a consulta expandida será pior que a consulta simples, uma vez que muitos documentos que contém os termos 'disse' e 'é' não teram relação nenhuma com os termos 'dilma' e 'aécio'\n",
    "\n",
    "Já no outro caso, a consulta expandida para discriminalização será melhor, já que o usuário poderia querer se informar da discriminalização de algo especifico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A expansão de consultas é mais adequada para melhorar o recall ou o precision? Por que?\n",
    "\n",
    "Se forem recuperados muitos documentos e poucos deles forem relevantes:\n",
    "O recall aumenta e o precision diminui\n",
    "\n",
    "Se a quantidade de documentos relevantes for proxima ao número de documentos recuperados:\n",
    "O precision aumenta e o recall diminui\n",
    "\n",
    "Em geral, como a expansão de consulta recupera muitos documentos, é mais adequada para melhorar o recall"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
